# A1 (dense baseline) - tuned to be a fair accuracy baseline while keeping
# training throughput manageable.
#
# Key idea:
# - Keep window retention for TRAIN to bound clip count (but not too aggressive)
# - Use a slightly larger budget for EVAL to avoid missing the action segment
# - For A main table: train/eval both use clip_len=16 (stable & easy to explain)
#
# NOTE: requires utils/data_ucf101.py support for *_train / *_eval keys.

includes: [configs/ast2_ucf101_dense.yaml]

model:
  # Dense baseline should not enable AST pruning in any form.
  use_ast_prune: false

data:
  # Main-table protocol: eval uses the same temporal length as training
  clip_lens_train: [16]
  clip_lens_eval: [16]

  # Control overall clip count via stride instead of over-aggressive retention
  train_stride_ratio: 0.75
  eval_stride_ratio: 0.75

  window_retention:
    enabled: true
    # Train-time budget (moderate; reduces precision drop vs very aggressive=4)
    max_windows_per_video_per_len_train: 8
    # Eval-time budget (slightly larger than train; still bounded)
    max_windows_per_video_per_len_eval: 16
    # Candidate pool for eval selection
    eval_candidates: 192

test:
  # Avoid late-run crashes from final test; run it manually from best.ckpt.
  run_final_test: false
