model:
  type: "VideoViT"
  img_size: 224
  num_frames: 8
  num_classes: 101
  embed_dim: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4.0
  patch_size: 16
  in_chans: 3
  drop_rate: 0.0
  attn_drop: 0.0
  drop_path_rate: 0.0
  use_ast_prune: true

data:
  dataset: "ucf101"
  frames_root: "data/ucf101/frames"
  splits_root: "data/ucf101/splits"
  audio_root: "data/ucf101/audio"
  train_split: "trainlist01.txt"
  test_split: "testlist01.txt"
  val_split: "testlist01.txt"
  clip_lens: [8, 16]
  clip_lens_train: [16]
  clip_lens_eval: [8, 16]
  num_frames: 8
  use_audio: false
  train_stride_ratio: 0.5
  eval_stride_ratio: 0.5
  clip_jitter: true
  img_size: 224
  num_workers: 8
  audio_feat_dim: 128
  window_retention:
    enabled: true
    max_windows_per_video_per_len: 4
    eval_candidates: 128
    global_frames: 8
    lambda_dist: 0.5
    alpha: 0.5
    space_weight: 0.5
    time_weight: 0.5
    min_gap: 8
    temporal_delta: 1
    downsample: 32
    entropy_bins: 32

audio:
  feat_dim: 128

train:
  device: "cuda:0"
  epochs: 50
  batch_size: 16
  lr: 3e-4
  weight_decay: 0.05
  warmup_epochs: 5
  amp: true

ast:
  use_ast_prune: true
  time_window_levels: [1, 2, 4]
  space_window_levels: [1, 2, 4]
  time_window_overlap: 0.5
  entropy_tau: 1.0
  rho_token_target: 0.5
  token_temperature: 0.1
  num_regions: 8
  alpha_time: 1.0
  beta_space: 0.5
  gamma_region: 0.5
  loss:
    lambda_token: 0.1
    lambda_head: 0.1
    lambda_ch: 0.1
    lambda_block: 0.05

hw:
  mode: "version_c_full"
  device_name: "RTX3090_FP16"
  gpu_yaml: "./configs/gpu_data.yaml"
  # NEW tabular proxy root (real per-device dir will be proxy_ckpts/<device_name>/)
  weight_dir: "./proxy_ckpts"
  proxy_weight_dir: "./proxy_ckpts"
  # v5.4: do NOT use legacy direct-sum HW loss; StableHW will control lambda_hw_effective.
  lambda_hw: 0.0
  lambda_T: 1.0e-3
  lambda_E: 1.0e-4
  lambda_mem: 1.0e-4
  lambda_area: 1.0e-6
  lambda_chip: 1.0e-3
  lambda_boundary: 1.0e-3
  lambda_overlap: 1.0e-3
  lambda_comm_extra: 1.0e-6
  lambda_thermal: 1.0e-4
  area_limit_mm2: 70000.0
  num_slots: 16
  wafer_radius_mm: 150.0
  latency_mode: "balanced"
  use_fine_split: true

mapping:
  strategy: "greedy_local"
  mem_limit_factor: 0.9
  seg_block_size: 2

training:
  mode: "version_c_full"
  model_type: "video"
  outer_epochs: 10
  inner_steps_ast: 100
  inner_steps_alpha: 20
  inner_steps_layout: 20

loss:
  lambda_AST: 1.0
  # v5.4: do NOT add hw loss directly into task loss (Acc-First Hard Gating).
  lambda_hw: 0.0

chiplet:
  candidate_types: ["RTX4090_FP16", "RTX3090_FP16", "RTX2080Ti_FP16"]
  tau_init: 5.0
  tau_min: 0.5
  tau_decay: 0.9

partition:
  w_latency: 1.0
  w_comm: 1.0e-3
  w_balance: 0.1
  min_split_gain_ratio: 0.05
  flops_ratio_thresh: 0.3
  traffic_ratio_thresh: 0.3
  max_split_layers: 4
  max_groups_per_layer: 2
  max_new_segments: 32

stable_hw:
  no_double_scale:
    enabled: true
  discrete_ops:
    relocate: { enabled: true }
    swap: { enabled: true }
    assign: { enabled: true }
  continuous_ops: {}
  no_drift:
    enabled: true
    freeze_baseline_stats: false
  normalize:
    enabled: false
    use_baseline_stats: false
    baseline_stats_path: ""
    scheme: "none"
    ref_update: "frozen"
  lambda_hw_schedule:
    enabled: false
    start_epoch: 0
    end_epoch: 0
    warmup_epochs: 0
    final_lambda_hw: 0.0
    freeze_schedule_in_recovery: true
